{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID3 Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make different subsets of data\n",
    "\n",
    "#Make Decision Tree Model\n",
    "\n",
    "\n",
    "\n",
    "#REQUIRES THAT LABEL KEY IN DATA POINT IS CALLED \"LABEL\"\n",
    "class DecisionTreeNode():\n",
    "    \n",
    "    def __init__(self, child_node1, threshold, child_node2, predict, feat):\n",
    "        self.child1 = child_node1\n",
    "        self.threshold = threshold\n",
    "        self.child2 = child_node2\n",
    "        self.predict = predict\n",
    "        self.feat = feat\n",
    "        \n",
    "    def goto(self, val):\n",
    "        \n",
    "        if self.predict is not None:\n",
    "            return self.predict\n",
    "        \n",
    "        if val[self.feat] > self.threshold:\n",
    "            return self.child1.goto(val)\n",
    "        else:\n",
    "            return self.child2.goto(val)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def putting_it_all_together(training, max_depth):\n",
    "    \n",
    "    if len(training) == 0:\n",
    "        return\n",
    "    \n",
    "    thresholds = []\n",
    "    \n",
    "    sorted_features = []\n",
    "    keys = list(training[0].keys())\n",
    "    for k in keys:\n",
    "        sorted_features.append([])\n",
    "        thresholds.append([])\n",
    "    for t in training:\n",
    "        for i in range(len(keys)):\n",
    "            if keys[i] == 'label':\n",
    "                continue\n",
    "            sorted_features[i].append(t[keys[i]])\n",
    "    \n",
    "    \n",
    "    for i in range(len(keys)):\n",
    "        sorted_features[i].sort()\n",
    "        \n",
    "        for j in range(len(sorted_features[i])-1):\n",
    "            thresholds[i].append((sorted_features[i][j]+sorted_features[i][j+1])/2)\n",
    "        \n",
    "        \n",
    "    print(thresholds)\n",
    " \n",
    "    parent_node = DecisionTreeNode(None, None, None, None, None)\n",
    "    \n",
    "    if max_depth == None:\n",
    "        recursion(training, thresholds, 1, parent_node, float(\"inf\"), 0)\n",
    "    else:\n",
    "        recursion(training, thresholds, 1, parent_node, max_depth, 0)\n",
    "    \n",
    "    return parent_node\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def recursion(parent_training_subset, thresholds, parent_entropy, cur_node, max_depth, cur_depth):\n",
    "       \n",
    "\n",
    "    check_if_good = get_prob_of_splits(parent_training_subset)\n",
    "    if 1 in check_if_good:\n",
    "        cur_node.predict = parent_training_subset[0]['label']\n",
    "        return\n",
    "          \n",
    "        \n",
    "    max_info_gain = -float(\"inf\")\n",
    "    max_thresh = 0\n",
    "    max_feat = 0\n",
    "    \n",
    "    #thresholds1 = copy.deepcopy(thresholds)\n",
    "    #thresholds2 = copy.deepcopy(thresholds)\n",
    "\n",
    "    predict1 = False\n",
    "    predict2 = False\n",
    "    \n",
    "    \n",
    "    keys = list(parent_training_subset[0].keys())\n",
    "    for i in range(len(thresholds)):\n",
    "        for j in range(len(thresholds[i])):\n",
    "        \n",
    "            #can I speed this up???\n",
    "            split1_ = []\n",
    "            split2_ = []\n",
    "\n",
    "            for p in parent_training_subset:\n",
    "                if p[keys[i]] > thresholds[i][j]:\n",
    "                    split1_.append(p)\n",
    "                else:\n",
    "                    split2_.append(p)\n",
    "            \n",
    "            prob1_li = get_prob_of_splits(split1_)\n",
    "            prob2_li = get_prob_of_splits(split2_)\n",
    "            val = thresholds[i][j]\n",
    "            \n",
    "            #if 1 in prob1_li:\n",
    "            #    print(\"1: \", prob1_li)\n",
    "            #    del thresholds1[i][j]\n",
    "            #elif 1 in prob2_li:\n",
    "            #    print(\"2: \", prob2_li)\n",
    "            #    del thresholds2[i][j]\n",
    "                    \n",
    "            info_gain = parent_entropy-(entropy(prob1_li)*(len(split1_)/len(parent_training_subset)) +\n",
    "                                            entropy(prob2_li)*(len(split2_)/len(parent_training_subset)))\n",
    "\n",
    "            \n",
    "            if info_gain > max_info_gain:\n",
    "                max_info_gain = info_gain\n",
    "                max_feat = i\n",
    "                max_thresh = val\n",
    "                \n",
    "    \n",
    "    split1 = []\n",
    "    split2 = []\n",
    "    for p in parent_training_subset:\n",
    "        if p[keys[max_feat]] > max_thresh:\n",
    "            split1.append(p)\n",
    "        else:\n",
    "            split2.append(p)\n",
    "            \n",
    "    #I don't scale this????? entropy1*len(split1)/len(parent)?\n",
    "    entropy1 = entropy(get_prob_of_splits(split1))\n",
    "    entropy2 = entropy(get_prob_of_splits(split2))\n",
    "    \n",
    "    print(parent_training_subset, thresholds, parent_entropy)\n",
    "    \n",
    "    d1 = DecisionTreeNode(None, None, None, None, None)\n",
    "    d2 = DecisionTreeNode(None, None, None, None, None)\n",
    "    cur_node.threshold = max_thresh\n",
    "    cur_node.child1 = d1\n",
    "    cur_node.child2 = d2\n",
    "    cur_node.feat = keys[max_feat]\n",
    "\n",
    "    \n",
    "    if entropy1 == 0:\n",
    "        cur_node.child1.predict = split1[0]['label']\n",
    "    elif (cur_depth+1) >= max_depth:\n",
    "        cur_node.child1.predict = most_common_label(split1)\n",
    "    else:\n",
    "        recursion(split1, thresholds, entropy1, d1, max_depth, cur_depth+1)\n",
    "        print(\"left\")\n",
    "        \n",
    "    if entropy2 == 0:\n",
    "        cur_node.child2.predict = split2[0]['label']\n",
    "    elif (cur_depth+1) >= max_depth:\n",
    "        cur_node.child2.predict = most_common_label(split2)\n",
    "    else:\n",
    "        recursion(split2, thresholds, entropy2, d2, max_depth, cur_depth+1)\n",
    "        print(\"right\")\n",
    "        \n",
    "    \n",
    "    \n",
    "def most_common_label(t_set):\n",
    "    occurences = {}\n",
    "    for t in t_set:\n",
    "        if t[\"label\"] not in occurences:\n",
    "            occurences[t[\"label\"]] = 0\n",
    "        else:\n",
    "            occurences[t[\"label\"]] += 1\n",
    "        \n",
    "    return max(occurences, key=occurences.get)\n",
    "\n",
    "def most_common_label_basic(t_set):\n",
    "    occurences = {}\n",
    "    for t in t_set:\n",
    "        if t not in occurences:\n",
    "            occurences[t] = 0\n",
    "        else:\n",
    "            occurences[t] += 1\n",
    "        \n",
    "    return max(occurences, key=occurences.get)\n",
    "\n",
    "\n",
    "\n",
    "def get_prob_of_splits(split):\n",
    "    dict_values = {}\n",
    "    for s in split:\n",
    "        if s['label'] not in dict_values:\n",
    "            dict_values[s['label']] = 1\n",
    "        else:\n",
    "            dict_values[s['label']] += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    #number of occurences in each class/num of all occurences\n",
    "    return [v/len(split) for v in dict_values.values()]\n",
    "\n",
    "\n",
    "#probability of each class in each split\n",
    "def entropy(P):\n",
    "    s = 0\n",
    "    for p in P:\n",
    "        s += p*math.log(p, 2)\n",
    "        \n",
    "    return -1*s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [1.0, 3.5, 5.5]]\n",
      "[{'label': 0, 'hi': 5}, {'label': 1, 'hi': 2}, {'label': 3, 'hi': 6}, {'label': 2, 'hi': 0}] [[], [1.0, 3.5, 5.5]] 1\n",
      "[{'label': 0, 'hi': 5}, {'label': 3, 'hi': 6}] [[], [1.0, 3.5, 5.5]] 1.0\n",
      "left\n",
      "[{'label': 1, 'hi': 2}, {'label': 2, 'hi': 0}] [[], [1.0, 3.5, 5.5]] 1.0\n",
      "right\n",
      "\n",
      "Max Depth Decreased\n",
      "\n",
      "[[], [1.0, 3.5, 5.5]]\n",
      "[{'label': 0, 'hi': 5}, {'label': 1, 'hi': 2}, {'label': 3, 'hi': 6}, {'label': 2, 'hi': 0}] [[], [1.0, 3.5, 5.5]] 1\n"
     ]
    }
   ],
   "source": [
    "#case 1\n",
    "training_set = []\n",
    "\n",
    "putting_it_all_together(training_set, None)\n",
    "\n",
    "\n",
    "\n",
    "#case 2\n",
    "#wait.... label will get counted as a feature...\n",
    "training_set = [{'label' : 0, 'hi':5}, {'label' : 1, 'hi':2}, {'label': 3, 'hi':6}, {'label': 2, 'hi':0}]\n",
    "\n",
    "DTree = putting_it_all_together(training_set, 2)\n",
    "\n",
    "print()\n",
    "print(\"Max Depth Decreased\")\n",
    "print()\n",
    "\n",
    "SmallerDTree = putting_it_all_together(training_set, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "3 0\n",
      "2 1\n"
     ]
    }
   ],
   "source": [
    "for t in training_set:\n",
    "    print(DTree.goto(t), SmallerDTree.goto(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make many decision trees \n",
    "#sample training with replacement\n",
    "\n",
    "\n",
    "class RandomForest():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.decision_trees = []\n",
    "        \n",
    "    def majority_vote(self, val):\n",
    "        votes = [v.goto(val) for v in self.decision_trees]\n",
    "        \n",
    "        return most_common_label_basic(votes)\n",
    "\n",
    "\n",
    "def random_forest_many_trees(training, max_depth, training_size, num_decision_trees):\n",
    "    \n",
    "    forest = RandomForest()\n",
    "    \n",
    "    for _ in range(num_decision_trees):\n",
    "    \n",
    "        #same training set, sample with replacement\n",
    "        cur_training_set = []\n",
    "        for i in range(training_size):\n",
    "            rand_ind = random.randint(0, len(training)-1)\n",
    "            cur_training_set.append(training[rand_ind])\n",
    "    \n",
    "        print(cur_training_set)\n",
    "        forest.decision_trees.append(putting_it_all_together(cur_training_set, max_depth))\n",
    "        \n",
    "    return forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 3, 'hi': 6}, {'label': 3, 'hi': 6}]\n",
      "[[], [6.0]]\n",
      "[{'label': 2, 'hi': 0}, {'label': 1, 'hi': 2}]\n",
      "[[], [1.0]]\n",
      "[{'label': 2, 'hi': 0}, {'label': 1, 'hi': 2}] [[], [1.0]] 1\n",
      "[{'label': 0, 'hi': 5}, {'label': 3, 'hi': 6}]\n",
      "[[], [5.5]]\n",
      "[{'label': 0, 'hi': 5}, {'label': 3, 'hi': 6}] [[], [5.5]] 1\n",
      "[{'label': 1, 'hi': 2}, {'label': 0, 'hi': 5}]\n",
      "[[], [3.5]]\n",
      "[{'label': 1, 'hi': 2}, {'label': 0, 'hi': 5}] [[], [3.5]] 1\n",
      "[{'label': 3, 'hi': 6}, {'label': 2, 'hi': 0}]\n",
      "[[], [3.0]]\n",
      "[{'label': 3, 'hi': 6}, {'label': 2, 'hi': 0}] [[], [3.0]] 1\n"
     ]
    }
   ],
   "source": [
    "r1 = random_forest_many_trees(training_set, None, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "\n",
      "Actual:\n",
      "0\n",
      "1\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for t in training_set:\n",
    "    print(r1.majority_vote(t))\n",
    "    \n",
    "print()\n",
    "print(\"Actual:\")\n",
    "for a in training_set:\n",
    "    print(a[\"label\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
